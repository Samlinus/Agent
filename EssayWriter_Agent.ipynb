{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f9374d-9609-405b-82bc-f35abcc46858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\r\n",
    "from typing import TypedDict, Annotated, List\r\n",
    "import operator\r\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\r\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063439fb-6fcf-4a21-a4af-436f32fbc9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2f7807-e9c9-4098-b710-4c5dfaebbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "import sqlite3\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba1d931-cfd3-479f-a2aa-c78e879d7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str # Human input - for which the essay is gonna be written.\n",
    "    plan: str # Key to keep track of plan\n",
    "    draft: str # Draft of essay\n",
    "    critique: str # Key for critique\n",
    "    content: List[str] # Key that keeps track of list of documents that tavily has researched & come back with\n",
    "    # Gonna be used in criteria to decide, if to stop.\n",
    "    revision_number: int # No. of revision we made.\n",
    "    max_revisions: int # Max revisions we wanna make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daba068-e48f-4790-9a49-b1370360eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa02a3e-bdc3-4e6c-b03f-7f956e7e67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8554a3e0-0c34-45e1-82c2-5c79640d66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "139eec95-cdd3-4ac1-a5ed-8ec92b987d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e09da5-3fc2-451f-9ae1-d3e9cb2be4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d7f236a-7662-4236-91fb-a7553937c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SamClitusFernando\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b3e900-a05f-4fb0-8e65-4adddf931aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilyClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "273f82bc-858f-46d0-8c42-24c97f1eb2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e4d003e-f455-407b-94a6-eec970d6acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b437475-e9de-4ea1-8862-7de3bd5e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7e7bc79-7a7a-4134-8494-57ccea53115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19ff7e93-6101-45bf-b09f-99caa7a8fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34cffc8-6b31-4969-a931-033cb15cdbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49482c11-c7c9-428d-9a83-6b20c7c1c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dfc8443-63c0-45b2-ad3e-49adac00450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c7f01774a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2be593b-4d56-4c69-9ef2-45d3ccaf4100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c7f01774a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e149e4bf-3f69-456a-8c66-2e85a0d7aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c7f01774a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    # output of should continue..\n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16ebffc8-ffba-4d37-a47e-b2adcd527ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c7f01774a0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80bc0d7a-61dd-47f7-a3e0-c3f767681fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating memory...\n",
    "sqlite_conn = sqlite3.connect(\"checkpoints.sqlite\", check_same_thread=False)\n",
    "memory = SqliteSaver(sqlite_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b8020c0-cfd7-4fb0-a8fe-abf583bb8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building graph..\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91caa815-e27f-4a78-81c3-a30dcd5a8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c460f8d2-0682-4db7-84f1-09f8f499b0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': \"## Essay Outline: LangChain vs. LangSmith: Two Sides of the LLM Application Coin\\n\\n**I. Introduction**\\n\\n*   **Hook:** Start with a compelling anecdote or observation about the growing complexity of LLM application development.\\n*   **Context:** Briefly introduce Large Language Models (LLMs) and the challenges developers face in building robust and reliable applications around them.\\n*   **Thesis Statement:**  LangChain and LangSmith represent distinct yet complementary approaches to LLM application development. LangChain provides the building blocks and framework, while LangSmith focuses on the monitoring, debugging, and iterative improvement process.  Understanding their differences is crucial for choosing the right tools for your project.\\n\\n**II. LangChain: The Building Blocks of LLM Applications**\\n\\n*   **What is LangChain?** Define LangChain as a framework specifically designed to simplify the development of applications powered by LLMs.\\n*   **Key Features and Functionality:**\\n    *   **Chains:** Explain how LangChain facilitates the creation of complex workflows by chaining together different LLM calls, prompts, and other tools. Provide specific examples like sequential chains, parallel chains, etc.\\n    *   **Modules:** Detail the various modules LangChain offers, such as Models, Prompts, Memory, Indexes, and Agents. Explain the purpose and benefits of each module with practical illustrations.\\n    *   **Integration Capabilities:** Highlight LangChain's ability to integrate with various LLMs, vector databases, and other external tools. Emphasize the flexibility this offers developers.\\n*   **Use Cases:** Showcase real-world examples of applications built using LangChain, demonstrating its practicality and versatility.\\n\\n**III. LangSmith: The Debugging and Observability Platform**\\n\\n*   **What is LangSmith?** Define LangSmith as a platform dedicated to monitoring, debugging, and improving LLM applications.\\n*   **Key Features and Functionality:**\\n    *   **Tracing:** Explain how LangSmith traces LLM interactions, providing detailed logs and insights into the chain of operations.\\n    *   **Debugging:** Describe the debugging capabilities offered by LangSmith, like visualizing chains, inspecting intermediate steps, and identifying bottlenecks.\\n    *   **Experiment Tracking:** Explain how LangSmith helps track different versions of prompts, chains, and models, enabling developers to compare performance and iterate effectively.\\n    *   **Evaluation and Feedback:** Discuss how LangSmith facilitates evaluating LLM outputs and gathering user feedback to refine application behavior.\\n*   **Use Cases:** Illustrate how LangSmith can be used to improve specific aspects of LLM applications, such as enhancing accuracy, reducing latency, or improving user experience.\\n\\n**IV.  LangChain and LangSmith: A Synergistic Relationship**\\n\\n*   **Integration:** Explain how LangChain and LangSmith can be integrated to create a complete development and monitoring workflow.\\n*   **Complementary Strengths:** Emphasize how LangChain's building blocks and LangSmith's observability features work together to streamline the development process.\\n*   **Benefits of Combined Use:** Discuss the advantages of using both tools, such as faster debugging, improved performance, and enhanced reliability of LLM applications.\\n\\n**V. Conclusion**\\n\\n*   **Recap:** Briefly summarize the key differences and functionalities of LangChain and LangSmith.\\n*   **Future Implications:** Discuss the potential impact of these tools on the future of LLM application development.\\n*   **Final Thought:** Offer a concluding thought on the importance of choosing the right tools for developing robust and impactful LLM applications.\\n\\n\\n**Notes:**\\n\\n*   Use clear and concise language throughout the essay.\\n*   Provide concrete examples and real-world applications to illustrate the concepts.\\n*   Maintain a neutral tone and avoid overly promotional language for either tool.\\n*   Consider including diagrams or visuals to further clarify the functionalities of LangChain and LangSmith.\\n*   Ensure proper citation of any external sources used.\\n\"}}\n",
      "{'research_plan': {'content': ['If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"Introduction LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. While both tools are designed to support LLM development, they serve different purposes and offer distinct benefits. In this blog, we'll delve into the differences between LangChain and LangSmith, their pros and\", 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"In this blog, we'll delve into the differences between LangChain and LangSmith, their pros and cons, and when to use each one. LangChain. LangChain is an open-source Python package that provides a framework for building and deploying LLM applications. It allows developers to create prototypes quickly and easily, making it an ideal choice for\", 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Jun 29, 2024 · LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready']}}\n",
      "{'generate': {'draft': '## LangChain vs. LangSmith: Two Sides of the LLM Application Coin\\n\\nThe rise of large language models (LLMs) has opened exciting new frontiers in application development.  However, building robust and reliable LLM-powered applications presents unique challenges, from managing complex workflows to ensuring consistent performance.  LangChain and LangSmith, both developed by LangChain Inc., offer distinct yet complementary approaches to tackling these challenges. LangChain provides the foundational building blocks for constructing LLM applications, while LangSmith focuses on the crucial aspects of monitoring, debugging, and iterative improvement. Understanding their differences is paramount for selecting the right tools for your project.\\n\\nLangChain is an open-source framework designed to streamline the development of LLM-powered applications. It empowers developers to create sophisticated workflows by chaining together various components.  These \"chains\" can orchestrate sequences of LLM calls, integrate external data sources, and incorporate other tools.  For example, a sequential chain might first extract information from a document using an LLM, then use another LLM to summarize the extracted information. LangChain also provides a modular structure with key components like Models, for accessing various LLMs; Prompts, for managing and optimizing prompts; Memory, for maintaining context across interactions; Indexes, for structuring and accessing external data; and Agents, for creating autonomous, task-oriented applications.  Its ability to integrate with a wide range of LLMs, vector databases, and other tools offers developers unparalleled flexibility.  Real-world applications built using LangChain include chatbots, question-answering systems, and generative writing tools, showcasing its practical versatility.\\n\\nLangSmith, on the other hand, functions as a debugging and observability platform specifically for LLM applications. It provides deep insights into the inner workings of your LLM workflows, enabling effective monitoring and iterative refinement.  LangSmith\\'s tracing capabilities meticulously log LLM interactions, providing a detailed record of each step in the chain of operations. Its debugging tools allow developers to visualize the execution flow, inspect intermediate values, and pinpoint bottlenecks or errors.  Moreover, LangSmith facilitates experiment tracking, enabling developers to compare the performance of different prompts, chains, and models, fostering data-driven optimization.  Its evaluation and feedback mechanisms streamline the process of assessing LLM outputs and gathering user feedback to enhance application behavior.  By using LangSmith, developers can identify and address issues like inaccurate responses, high latency, or suboptimal user experiences, leading to more robust and performant applications.\\n\\nWhile distinct in their focus, LangChain and LangSmith operate synergistically. They can be seamlessly integrated to create a comprehensive development and monitoring workflow. LangChain provides the building blocks for constructing the application logic, while LangSmith offers the tools to observe, analyze, and refine its behavior in practice.  This combined approach accelerates the debugging process, improves overall performance, and enhances the reliability of LLM applications.  Leveraging both tools empowers developers to move from prototype to production with greater confidence and efficiency.\\n\\nIn conclusion, LangChain and LangSmith represent two essential facets of LLM application development. LangChain equips developers with the framework and components to build sophisticated LLM workflows, while LangSmith provides the tools for monitoring, debugging, and continuous improvement.  Their combined use offers a powerful approach to building robust and impactful LLM applications. As the LLM landscape continues to evolve, leveraging tools like LangChain and LangSmith will be increasingly crucial for navigating the complexities and unlocking the full potential of this transformative technology.\\n', 'revision_number': 2}}\n",
      "{'reflect': {'critique': 'This is a good starting point for an essay comparing LangChain and LangSmith. It provides a clear overview of both tools and highlights their complementary nature. However, there\\'s room for improvement in terms of depth, analysis, and engagement with the reader.\\n\\n**Critique and Recommendations:**\\n\\n* **Expand on the \"Why\":** While you mention the challenges of building LLM applications, delve deeper into *why* these challenges exist. Discuss the inherent unpredictability of LLMs, the difficulty of managing prompts, the importance of context management, and the need for robust error handling.  This will provide a stronger foundation for understanding the value proposition of both tools.  A stronger opening would hook the reader by illustrating a specific problem scenario in LLM development.\\n\\n* **Deeper Dive into Features:**  While you list some features, provide more concrete examples and use cases.  \\n    * **LangChain:**  Explain different chain types (not just sequential) like Router Chains or Agent Chains.  Provide a more detailed example of how indexes are used, perhaps with a specific vector database like FAISS or Pinecone.  Show, don\\'t just tell.  Code snippets illustrating key functionalities would be beneficial.\\n    * **LangSmith:**  Elaborate on the types of insights provided.  How does LangSmith help with prompt engineering and optimization?  Discuss specific metrics tracked, like cost per token, latency, or error rates. How does feedback integration work in practice?\\n\\n* **Comparative Analysis:**  The essay currently describes each tool separately.  Strengthen the comparison by directly contrasting their functionalities.  Create a table summarizing key features side-by-side. Discuss scenarios where one tool might be preferred over the other, or where they are best used together.  For instance, how does LangSmith\\'s debugging complement LangChain\\'s modularity?\\n\\n* **Real-World Examples:** While you mention application types, provide more concrete examples of how LangChain and LangSmith are used in real-world projects.  This could involve case studies, specific company implementations, or links to open-source projects.\\n\\n* **Address Limitations:** No tool is perfect.  Discuss the limitations of both LangChain and LangSmith.  Are there specific types of LLM applications where they are less suitable?  What are the potential drawbacks of their integration?  Addressing limitations adds credibility and provides a more balanced perspective.\\n\\n* **Target Audience and Length:** Consider your target audience. Are you writing for experienced developers, LLM beginners, or a broader technical audience?  Adjust the technical depth accordingly.  Aim for a more substantial essay, around 1500-2000 words, to accommodate the recommended additions.\\n\\n* **Engaging Style:**  Use a more active voice and incorporate real-world analogies to make the concepts more relatable.  Pose questions to the reader to encourage critical thinking.  Conclude with a compelling call to action, encouraging readers to explore both tools and contribute to their development (if open-source).\\n\\n\\nBy addressing these points, you can transform this good overview into a compelling and informative essay that provides a deep understanding of LangChain and LangSmith and their crucial roles in the evolving landscape of LLM application development.\\n'}}\n",
      "{'research_critique': {'content': ['If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"Introduction LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. While both tools are designed to support LLM development, they serve different purposes and offer distinct benefits. In this blog, we'll delve into the differences between LangChain and LangSmith, their pros and\", 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"In this blog, we'll delve into the differences between LangChain and LangSmith, their pros and cons, and when to use each one. LangChain. LangChain is an open-source Python package that provides a framework for building and deploying LLM applications. It allows developers to create prototypes quickly and easily, making it an ideal choice for\", 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Jun 29, 2024 · LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Jun 29, 2024 · LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications.Missing:  cases | Show results with:cases', 'The challenges faced by developers in this field are becoming more intricate than ever. If you are on the verge of, or already amidst implementing LLM applications, you might have stumbled upon…', \"In this blog, we discuss the challenges of LLM application development beyond the prototype and why Apache Airflow® was highlighted by Andreessen Horowitz's Emerging Architectures for LLM Applications for its ability to enable day-2 operations for LLM applications.\", 'Oct 12, 2023 · LangSmith is a platform for building production-grade LLM applications. It lets you debug, test, evaluate, and monitor chains and intelligent agents built on\\xa0...Missing:  metrics | Show results with:metrics', 'LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a\\xa0...Prototyping\\u200b · Beta Testing\\u200b · Production\\u200bMissing:  capabilities | Show results with:capabilities']}}\n",
      "{'generate': {'draft': 'The rise of large language models (LLMs) has revolutionized how we interact with technology, enabling applications from conversational AI to sophisticated code generation.  However, building robust and reliable LLM applications presents significant challenges for developers.  Navigating the complexities of prompt engineering, managing intricate workflows, and ensuring consistent performance requires specialized tools. This is where LangChain and LangSmith enter the picture.  LangChain and LangSmith represent distinct yet complementary approaches to LLM application development. LangChain provides the building blocks and framework, while LangSmith focuses on the monitoring, debugging, and iterative improvement process. Understanding their differences is crucial for choosing the right tools for your project.\\n\\nLangChain is an open-source framework specifically designed to simplify the development of applications powered by LLMs. Its core strength lies in its ability to create complex workflows called \"chains.\"  These chains link together various components, including LLM calls, prompts, and other tools. For instance, a sequential chain might first use an LLM to summarize a document, then pass that summary to another LLM for sentiment analysis.  LangChain also offers a modular structure with components like Models, for interacting with various LLMs; Prompts, for managing and optimizing prompts; Memory, for adding statefulness to chains; Indexes, for efficient data access; and Agents, for creating autonomous decision-making systems.  Furthermore, LangChain\\'s flexible integration capabilities allow developers to connect with a wide range of LLMs, vector databases, and other tools, providing significant adaptability.  This versatility enables developers to build diverse applications, from chatbots and question-answering systems to code generation and data analysis tools.\\n\\nLangSmith, on the other hand, is not a framework for building applications but a platform dedicated to monitoring, debugging, and improving LLM applications.  It provides deep visibility into the execution of LLM workflows, offering crucial insights for optimizing performance and reliability.  LangSmith\\'s tracing functionality captures detailed logs of LLM interactions, allowing developers to follow the chain of operations step by step.  Its debugging capabilities enable visualizing chains, inspecting intermediate steps, and identifying bottlenecks.  Furthermore, LangSmith facilitates experiment tracking by allowing developers to manage different versions of prompts, chains, and models, enabling performance comparisons and efficient iteration.  The platform also supports evaluation and feedback mechanisms, helping developers assess LLM outputs and gather user feedback to refine application behavior.  This is invaluable for improving aspects like accuracy, latency, and overall user experience.\\n\\nWhile distinct in their primary functions, LangChain and LangSmith can be integrated to create a comprehensive development and monitoring workflow.  LangChain provides the building blocks for creating the LLM application, while LangSmith offers the tools to observe, analyze, and refine its behavior in action. This synergistic relationship streamlines the development process considerably. Using both tools together allows for faster debugging, improved performance, and enhanced reliability of LLM applications.  Developers can quickly identify and address issues in their chains, experiment with different prompts and models, and gain data-driven insights to optimize their applications for real-world scenarios.\\n\\nIn conclusion, LangChain and LangSmith represent two essential sides of the LLM application development coin. LangChain empowers developers to build sophisticated LLM-powered applications with its flexible and modular framework, while LangSmith provides the observability and debugging tools crucial for ensuring these applications perform reliably and efficiently in production.  Their combined use signifies a significant step towards more robust, transparent, and iterative LLM application development. As the LLM landscape continues to evolve, leveraging the strengths of both tools will be crucial for building impactful and reliable applications that harness the full potential of this transformative technology.\\n', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1``,\n",
    "    \"content\": []\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279510e-613d-4a8e-87b4-a6cb5ba95471",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92cb45bc-11e1-4639-9f5a-3e126a794d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ewriter, writer_gui\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53f93f-043d-4b20-a5e4-2b2b073620e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
